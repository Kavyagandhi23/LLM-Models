{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['OPENAI_API_KEY']='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. Start by brushing up on your technical skills. Make sure you understand the basics of programming, data analysis, and machine learning.\n",
      "\n",
      "2. Understand the fundamentals of statistics, including linear algebra, calculus, probability, and Bayesian inference.\n",
      "\n",
      "3. Read and practice data science interview questions.\n",
      "\n",
      "4. Practice coding algorithms and data structures.\n",
      "\n",
      "5. Develop your data visualization skills.\n",
      "\n",
      "6. Take online courses to gain a better understanding of data science.\n",
      "\n",
      "7. Read books related to data science, such as Data Science from Scratch, Big Data: A Revolution That Will Transform How We Live, Work, and Think, and Practical Data Science with R.\n",
      "\n",
      "8. Follow blogs and online resources from the data science community.\n",
      "\n",
      "9. Participate in data science challenges and hackathons.\n",
      "\n",
      "10. Attend meetups and conferences related to data science.\n"
     ]
    }
   ],
   "source": [
    "text = \"How and from where to prepare for Data science interview for faang or maang companies as fresher?\"\n",
    "print(llm.predict(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Langchain App\\venv\\lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:127: FutureWarning: '__init__' (from 'huggingface_hub.inference_api') is deprecated and will be removed from version '1.0'. `InferenceApi` client is deprecated in favor of the more feature-complete `InferenceClient`. Check out this guide to learn how to convert your script to use it: https://huggingface.co/docs/huggingface_hub/guides/inference#legacy-inferenceapi-client.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from langchain import HuggingFaceHub\n",
    "llm_huggingface=HuggingFaceHub(repo_id=\"google/flan-t5-large\", model_kwargs={\"temperature\":0, \"max_length\":64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$70,000\n"
     ]
    }
   ],
   "source": [
    "output=llm_huggingface.predict('What is the annual expected salary for fresher in Data Scientist in Canada?')\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n\\nA new age of technology, is dawning before our eyes,\\nA branch of science that is often met with surprise.\\n\\nThe power of Artificial Intelligence, a vast array of potential,\\nAn incredible source of knowledge, that will make us more essential.\\n\\nWe'll be able to use AI, to make life more efficient,\\nFrom robotics to healthcare, it will offer an immense benefit.\\n\\nThe potential of AI, is so enormous and grand,\\nWe'll be able to tackle problems, in ways never seen before at hand.\\n\\nAI is changing the world, and transforming the way we live,\\nWe are now living in a time, where anything is possible to achieve.\\n\\nThe possibilities are endless, and the progress is so immense,\\nWe must be prepared for the future, for AI is here to commence.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict('Can you write a poem  on Artificial Intelligence technology?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Expected salary for Entry-level Data Scientist in Canada'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template=PromptTemplate(input_variables=['Country'],\n",
    "               template=\"Expected salary for Entry-level Data Scientist in {Country}\")\n",
    "\n",
    "prompt_template.format(Country='Canada')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mExpected salary for Entry-level Data Scientist in Canada\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "The salary for an entry-level data scientist in Canada can vary widely depending on the size of the company, the industry, and the specific role. According to Glassdoor, the average salary for a data scientist in Canada is $85,000 CAD per year. However, salaries can range from $60,000 to $110,000.\n"
     ]
    }
   ],
   "source": [
    "chain = LLMChain(llm=llm, prompt=prompt_template,verbose=True)\n",
    "print(chain.run(\"Canada\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining Multiple Template using Simple Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = PromptTemplate(input_variables=['Country'],\n",
    "                         template=\"Annual average salary for Entry-level Data Science position in {Country}\")\n",
    "\n",
    "chain = LLMChain(llm=llm, prompt=prompt1,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = PromptTemplate(input_variables=['Salary'],\n",
    "                         template = \"List of 7 Companies hires for Entry level position with {Salary}\")\n",
    "\n",
    "chain2 = LLMChain(llm=llm,prompt=prompt2, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnnual average salary for Entry-level Data Science position in Canada\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mList of 7 Companies hires for Entry level position with \n",
      "\n",
      "The average salary for an entry-level data science position in Canada is around $76,000 CAD per year. This number can vary significantly depending on the company, the city, and other factors.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\n1. Amazon: Amazon offers entry-level data science positions with an average salary of $80,000 CAD per year.\\n\\n2. Microsoft: Microsoft offers entry-level data science positions with an average salary of $76,000 CAD per year.\\n\\n3. Google: Google offers entry-level data science positions with an average salary of $92,000 CAD per year.\\n\\n4. Apple: Apple offers entry-level data science positions with an average salary of $89,000 CAD per year.\\n\\n5. IBM: IBM offers entry-level data science positions with an average salary of $78,000 CAD per year.\\n\\n6. Accenture: Accenture offers entry-level data science positions with an average salary of $78,000 CAD per year.\\n\\n7. Deloitte: Deloitte offers entry-level data science positions with an average salary of $80,000 CAD per year.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "ssqchain=SimpleSequentialChain(chains=[chain,chain2])\n",
    "ssqchain.run('Canada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mAnnual average salary for Entry-level Data Science position in Canada\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mList of 7 Companies hires for Entry level position with  is around C$60,000. Salaries may vary depending on skills, experience, location, and employer.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Country': 'Canada',\n",
       " 'input': 'Canada',\n",
       " 'output': '\\n\\n1. Salesforce \\n2. Amazon \\n3. Microsoft \\n4. IBM \\n5. Google \\n6. Oracle \\n7. Apple'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "salary_prompt = PromptTemplate(input_variables=['Country'],\n",
    "                               template = \"Average annual salary for Entry-level data Scientist position in {Country}\")\n",
    "chain_1 = LLMChain(llm=llm, prompt=salary_prompt, verbose=True, output_key='salary')\n",
    "\n",
    "comapnies_prompt=PromptTemplate(input_variables=['salary'],\n",
    "                                template='Comapnies that hire Entry-level Data Science student with {salary}')\n",
    "chain_2 = LLMChain(llm=llm, prompt=comapnies_prompt, verbose=True,output_key='Companies')\n",
    "\n",
    "sqchain=SequentialChain(chains=[chain_1,chain_2], input_variables=['Country'], output_variables=['salary','Companies'])\n",
    "\n",
    "# Add the missing 'input' key to the input dictionary\n",
    "input_data = {'Country': 'Canada', 'input': 'Canada'}  # Replace 'some_value' with the actual input data\n",
    "\n",
    "# Call the SequentialChain with the modified input dictionary\n",
    "ssqchain(input_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatModels with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000022CDC1D1DC0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000022CDC1F8A60>, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatllm=ChatOpenAI(temperature=0.7, openai_api_key=os.environ['OPENAI_API_KEY'],model='gpt-3.5-turbo')\n",
    "chatllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
